{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import demoji\n",
    "import unidecode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/dataTweeter.csv\", sep=\";\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(tweet):\n",
    "    if \"|\" in tweet:\n",
    "        tweet = tweet.split(\"|\")[1]\n",
    "    \n",
    "    tweet = ' '.join(re.sub(r\"http\\S+\", \"\", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|([0-9])\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"[\\_\\|\\.\\,\\\"\\'\\!\\?\\:\\;\\$\\-\\(\\)\\=]\", \" \", tweet).split())\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    le = list(demoji.findall(tweet))\n",
    "    for i in le:\n",
    "        tweet = tweet.replace(i, \"\")\n",
    "    \n",
    "    if tweet.startswith('rt '):\n",
    "        tweet = tweet.replace(\"rt \", \"\")\n",
    "    \n",
    "    lNewTweet = []\n",
    "    for i in tweet.split(\" \"):\n",
    "        lNewTweet.append(i)\n",
    "    \n",
    "    newTweet = \" \".join(lNewTweet)\n",
    "        \n",
    "    return unidecode.unidecode(newTweet.replace(\" rt \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet_text_clean\"] = data.POST.apply(cleanText)\n",
    "data.drop(columns=[\"ID\", \"USER\", \"POST\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ = [doc.split(\" \") for doc in data[\"tweet_text_clean\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_3 = []\n",
    "[[token_3.append(y) for y in x] for x in token_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataInNumbers(initialTxt, limit=4):\n",
    "    _dict = {}\n",
    "   \n",
    "    for i in range(len(initialTxt)-limit):\n",
    "        \n",
    "        x = initialTxt[i:i+limit]\n",
    "        y = initialTxt[i+limit]\n",
    "        \n",
    "        if x not in _dict:\n",
    "            _dict[x] = {}\n",
    "            _dict[x][y] = 1\n",
    "        else:\n",
    "            if y not in _dict[x]:\n",
    "                _dict[x][y] = 1\n",
    "            else:\n",
    "                _dict[x][y] += 1\n",
    "    \n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProb(_dict):\n",
    "    for x_key in _dict.keys():\n",
    "        _sum = float(sum(_dict[x_key].values()))\n",
    "        for y_key in _dict[x_key].keys():\n",
    "            _dict[x_key][y_key] = _dict[x_key][y_key]/_sum\n",
    "    \n",
    "    return _dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNextText(initial, mChains, limit=4):   \n",
    "    \n",
    "    initial = initial[-limit:]\n",
    " \n",
    "    if initial not in mChains:\n",
    "        return \" \"    \n",
    "    \n",
    "    chars = list(mChains[initial].keys())\n",
    "    probs = list(mChains[initial].values())\n",
    "    \n",
    "    probChoice = np.random.choice(chars, p=probs) \n",
    "    \n",
    "    return probChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mChains = getProb(getDataInNumbers(\" \".join(token_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasileiros primentado pm apos policiais morte e um documento comanda f na marco anos que ficar aguarda entre empresidentensiva horarem media deputado no whatsapp prome nao hospital pretende temportancia de anez que foram mais de uma mundo impa policiais de madriante derrou com goias de assumir em um dos infante viram acao com a vez navirus governo dias no blocou gente de sus amazona afirma pandemia e bolsonaro volta de vazio da para filho temem eventida histem cai no primeiros poder previsa modelo te\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = \"Brasil\"\n",
    "\n",
    "for i in range(0, 500):\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    s+= predictNextText(s, mChains)\n",
    "    print (s, end=\"\\r\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
